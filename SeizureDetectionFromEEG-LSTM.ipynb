{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn import preprocessing\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset as torchDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "data_dir = '/home/ghn8/courses/neuroengineering/project/data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_training_data(pid):\n",
    "    ICTAL = 1\n",
    "    NONICTAL = 0\n",
    "    \n",
    "    ictal_data_dir = '/home/ghn8/courses/neuroengineering/project/data/patient_%d/ictal train/' % pid\n",
    "    nonictal_data_dir = '/home/ghn8/courses/neuroengineering/project/data/patient_%d/non-ictal train/' % pid\n",
    "    \n",
    "    train_inputs = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1, len(os.listdir(ictal_data_dir))+1):\n",
    "        file_path = os.path.join(ictal_data_dir, 'patient_%d_%d.mat' % (pid, i))\n",
    "        data_mat = sio.loadmat(file_path)\n",
    "        data = data_mat['data'].astype(np.float32)\n",
    "        if(np.isnan(data).any()):\n",
    "            raise(ValueError(\"NaN in ictal data\"))\n",
    "        train_inputs.append(data.T) # transpose data to get num_channels x timepoints\n",
    "        train_labels.append(ICTAL)\n",
    "    \n",
    "    for i in range(1, len(os.listdir(nonictal_data_dir))+1):\n",
    "        file_path = os.path.join(nonictal_data_dir, 'patient_%d_%d.mat' % (pid, i))\n",
    "        data_mat = sio.loadmat(file_path)\n",
    "        data = data_mat['data'].astype(np.float64)\n",
    "        if(np.isnan(data).any()):\n",
    "            raise(ValueError(\"NaN in non-ictal data\"))\n",
    "        train_inputs.append(data.T) # transpose data to get num_channels x timepoints\n",
    "        train_labels.append(NONICTAL)\n",
    "        \n",
    "    train_inputs = np.asarray(train_inputs)\n",
    "    train_labels = np.asarray(train_labels)\n",
    "    \n",
    "    return train_inputs, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_test_data(pid):\n",
    "    test_dir = '/home/ghn8/courses/neuroengineering/project/data/patient_%d/test/' % pid\n",
    "    \n",
    "    test_inputs = []\n",
    "    \n",
    "    for i in range(1, len(os.listdir(test_dir))+1):\n",
    "        file_path = os.path.join(test_dir, 'patient_%d_test_%d.mat' % (pid, i))\n",
    "        if os.path.exists(file_path):\n",
    "            data_mat = sio.loadmat(file_path)\n",
    "            data = data_mat['data'].astype(np.float32)\n",
    "            data = np.nan_to_num(data)\n",
    "            if(np.isnan(data).any()):\n",
    "                raise(ValueError(\"NaN in test data\"))\n",
    "            test_inputs.append(data.T) # transpose data to get num_channels x timepoints\n",
    "        \n",
    "    test_inputs = np.asarray(test_inputs)\n",
    "    \n",
    "    return test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PATIENTS = 7\n",
    "all_train_data = {}\n",
    "\n",
    "train_data_dump_file = os.path.join('/home/ghn8/courses/neuroengineering/project/preprocessed/all_data', 'all_train_data.pkl')\n",
    "\n",
    "if not os.path.exists(train_data_dump_file):\n",
    "    for pid in range(1, NUM_PATIENTS+1):\n",
    "        train_inputs, train_labels = get_patient_training_data(pid)\n",
    "        all_train_data['patient_%d' % pid] = { 'inputs': train_inputs, 'labels': train_labels}\n",
    "        print('Finished reading data for patient %d' % pid)\n",
    "\n",
    "    pickle.dump(all_train_data, open(train_data_dump_file, 'wb'))\n",
    "else:\n",
    "    all_train_data = pickle.load(open(train_data_dump_file, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data = {}\n",
    "\n",
    "test_data_dump_file = os.path.join('/home/ghn8/courses/neuroengineering/project/preprocessed/all_data', 'all_test_data.pkl')\n",
    "\n",
    "if not os.path.exists(test_data_dump_file):\n",
    "    for pid in range(1, NUM_PATIENTS+1):\n",
    "        test_inputs = get_patient_test_data(pid)\n",
    "        all_test_data['patient_%d' % pid] = test_inputs\n",
    "        print('Finished reading test data for patient %d' % pid)\n",
    "\n",
    "    pickle.dump(all_test_data, open(test_data_dump_file, 'wb'))\n",
    "else:\n",
    "    all_test_data = pickle.load(open(test_data_dump_file, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft(timeseries):\n",
    "    return np.log10(np.absolute(np.fft.rfft(timeseries)))\n",
    "\n",
    "def get_spectral_features(timeseries):\n",
    "    raw_fft = fft(timeseries)\n",
    "    mask = np.logical_or(np.isneginf(raw_fft), np.isinf(raw_fft))\n",
    "    raw_fft[mask] = 0.0;\n",
    "\n",
    "    return raw_fft\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(features, labels):\n",
    "    assert features.shape[0] == labels.shape[0], \"Mismatched number of samples\"\n",
    "    shuffled_indices = np.random.permutation(features.shape[0])\n",
    "    \n",
    "    shuffled_features = features[shuffled_indices, :]\n",
    "    shuffled_labels = labels[shuffled_indices]\n",
    "    return shuffled_features, shuffled_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs_to_spectral_features(inputs):\n",
    "    num_samples = inputs.shape[0]\n",
    "    features = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = inputs[i, :, :].squeeze()\n",
    "\n",
    "        spectral_features = get_spectral_features(sample)\n",
    "        features.append(spectral_features)\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ica_clean(data, n_components):\n",
    "    ica = FastICA(n_components=n_components)\n",
    "    return ica.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temporal_features(inputs, num_eigenvalues=-1, num_icas=0):\n",
    "    num_samples = inputs.shape[0]\n",
    "    features = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = inputs[i, :, :].squeeze()\n",
    "        \n",
    "        if num_icas > 0:\n",
    "            sample = ica_clean(sample, num_icas)\n",
    "        \n",
    "        norm_sample = preprocessing.scale(sample)\n",
    "        corr = np.corrcoef(norm_sample)\n",
    "        \n",
    "        uppper_triag_indices = np.triu_indices(corr.shape[0], 1)\n",
    "        upper_triag_vals = corr[uppper_triag_indices].ravel()\n",
    "        \n",
    "        eigenvalues, _ = np.linalg.eig(corr)\n",
    "        eigenvalues = np.sort(eigenvalues)\n",
    "        \n",
    "        if num_eigenvalues > 0:\n",
    "            eigenvalues = eigenvalues[:num_eigenvalues]\n",
    "\n",
    "        features.append(np.concatenate((upper_triag_vals, eigenvalues)))\n",
    "    features = np.asarray(features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs_to_features(inputs):\n",
    "    spectral_features = transform_inputs_to_spectral_features(inputs, lpf_freq)\n",
    "        \n",
    "    temporal_features = get_temporal_features(inputs)\n",
    "    \n",
    "    features = np.concatenate((spectral_features, spectral_features), axis=1)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_signal_by_windows(data, num_windows):\n",
    "    num_samples, num_timepoints, num_channels = data.shape\n",
    "    new_data = np.zeros((num_samples, num_windows, num_channels))\n",
    "    window = int(num_timepoints / num_windows)\n",
    "\n",
    "    for i in range(num_windows):\n",
    "        start_tp = i * window\n",
    "        end_tp = (i+1) * window\n",
    "        if i == (num_windows - 1):\n",
    "            end_tp = end_tp + 1\n",
    "        \n",
    "        window_data = np.mean(data[:, start_tp:end_tp, :], axis=1)\n",
    "        new_data[:, i, :] = window_data\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(torchDataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.features[index, :,  :].astype('float')\n",
    "        label = np.expand_dims(self.labels[index], axis=1)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "        self.num_layers = 1\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=self.num_layers)\n",
    "\n",
    "        self.hidden2out = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout_layer = nn.Dropout(p=0.1)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return(autograd.Variable(torch.randn(self.num_layers, batch_size, self.hidden_dim)),\n",
    "                autograd.Variable(torch.randn(self.num_layers, batch_size, self.hidden_dim)))\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        self.hidden = self.init_hidden(batch.size(1))\n",
    "\n",
    "        outputs, (ht, ct) = self.lstm(batch, self.hidden)\n",
    "\n",
    "        # ht is the last hidden state of the sequences\n",
    "        # ht = (1 x batch_size x hidden_dim)\n",
    "        # ht[-1] = (batch_size x hidden_dim)\n",
    "        output = self.dropout_layer(ht[-1])\n",
    "        output = self.hidden2out(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "def train(train_loader, num_epochs, num_in_channels, num_hidden, learning_rate):\n",
    "    model = LSTMClassifier(num_in_channels, num_hidden)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    # Training\n",
    "    total_step = len(train_loader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for i, (features, label) in enumerate(train_loader):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            features = np.swapaxes(features, 0, 1)\n",
    "            features = features.type(torch.FloatTensor)\n",
    "            label = label.type(torch.FloatTensor)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(features)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss / len(train_loader)\n",
    "        if ((epoch+1) % 1 == 0):\n",
    "            print(\"\\tEpoch [%d/%d], Loss: %.4f\" % (epoch+1, num_epochs, epoch_loss))\n",
    "        if epoch_loss <= 1e-4:\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict(model, test_loader):\n",
    "    # Test\n",
    "    model.eval()\n",
    "    predicted_probs = np.empty((0, 1))\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = np.swapaxes(inputs, 0, 1)\n",
    "            inputs = inputs.type(torch.FloatTensor)\n",
    "\n",
    "            probs = torch.sigmoid(model(inputs)).data.cpu().numpy()\n",
    "            predicted_probs = np.concatenate((predicted_probs, probs))\n",
    "    \n",
    "    return predicted_probs\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    # Test\n",
    "    model.eval()\n",
    "    \n",
    "    all_predicted_labels = np.empty((0, 1))\n",
    "    all_probs = np.empty((0, 1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = np.swapaxes(inputs, 0, 1)\n",
    "            inputs = inputs.type(torch.FloatTensor)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "\n",
    "            probs = torch.sigmoid(model(inputs)).data.cpu().numpy()\n",
    "            predicted_labels = np.where(probs > 0.5, 1, 0)\n",
    "\n",
    "            all_predicted_labels = np.concatenate((all_predicted_labels, predicted_labels))\n",
    "            all_probs = np.concatenate((all_probs, probs))\n",
    "    \n",
    "    return all_predicted_labels.squeeze(), all_probs.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"5\"\n",
    "is_testing = True\n",
    "\n",
    "for pid in range(1, NUM_PATIENTS+1):\n",
    "    train_inputs = all_train_data['patient_%d' % pid]['inputs']\n",
    "    train_labels = all_train_data['patient_%d' % pid]['labels']\n",
    "    test_inputs = all_test_data['patient_%d' % pid]\n",
    "    \n",
    "    output_file = os.path.join('/home/ghn8/courses/neuroengineering/project/gia/outputs', 'cnn_spectral_LSTM_decay1e-5_pid%d.csv' % pid)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    num_epochs = 20\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.1\n",
    "    num_hidden = 32\n",
    "\n",
    "    train_inputs = np.swapaxes(train_inputs, 1, 2)\n",
    "    test_inputs = np.swapaxes(test_inputs, 1, 2)\n",
    "    num_samples, num_timepoints, num_channels = train_inputs.shape\n",
    "    \n",
    "    if num_timepoints > 500:\n",
    "        train_inputs = compute_mean_signal_by_windows(train_inputs, 500)\n",
    "    print(train_inputs.shape)\n",
    "    print(test_inputs.shape)\n",
    "    \n",
    "    if is_testing:\n",
    "        print(\"Predicting patient %d\" % pid)\n",
    "        \n",
    "        fh = open(output_file, 'w')\n",
    "        if pid == 1:\n",
    "            fh.write(\"id,prediction\\n\")\n",
    "            \n",
    "        train_dataset = EEGDataset(features=train_inputs,\n",
    "                                  labels=train_labels)\n",
    "        test_dataset = EEGDataset(features=test_inputs,\n",
    "                                  labels=np.zeros((test_inputs.shape[0], 1)))\n",
    "\n",
    "        # Data loader\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False)\n",
    "\n",
    "        model = train(train_loader, num_epochs, num_channels, num_hidden, learning_rate)\n",
    "        predicted_probs = predict(model, test_loader)\n",
    "\n",
    "        for i in range(len(predicted_probs)):\n",
    "            fh.write(\"patient_%d_%d,%f\\n\" % (pid, i+1, predicted_probs[i]))\n",
    "        fh.close()\n",
    "    else:\n",
    "        print(\"Evaluating patient %d\" % pid)\n",
    "        val_fraction = 0.2\n",
    "\n",
    "        # creat training and validation data\n",
    "        [shuffled_features, shuffled_labels] = shuffle_data(train_inputs, train_labels)\n",
    "\n",
    "        num_val_samples = int(num_samples * val_fraction)\n",
    "\n",
    "        val_features = shuffled_features[:num_val_samples, :]\n",
    "        val_labels = shuffled_labels[:num_val_samples]\n",
    "\n",
    "        bootstraped_train_features = shuffled_features[num_val_samples:, :]\n",
    "        bootstraped_train_labels = shuffled_labels[num_val_samples:]\n",
    "        \n",
    "        train_dataset = EEGDataset(features=bootstraped_train_features,\n",
    "                                  labels=bootstraped_train_labels)\n",
    "        test_dataset = EEGDataset(features=val_features,\n",
    "                                  labels=val_labels)\n",
    "\n",
    "    \n",
    "        # Data loader\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=False)\n",
    "\n",
    "        model = train(train_loader, num_epochs, num_channels, num_hidden, learning_rate)\n",
    "        all_predicted_labels, all_probs = eval(model, test_loader)\n",
    "        accuracy = (all_predicted_labels == val_labels).sum() * 100.0 / val_labels.shape[0]\n",
    "        \n",
    "        print(\"Accuracy: %.2f\" % accuracy + \"%\")\n",
    "        print(\"AUC :\", roc_auc_score(val_labels, all_probs))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
