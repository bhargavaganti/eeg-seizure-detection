{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn import preprocessing\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "data_dir = '/home/ghn8/courses/neuroengineering/project/data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_training_data(pid):\n",
    "    ICTAL = 1\n",
    "    NONICTAL = 0\n",
    "    \n",
    "    ictal_data_dir = '/home/ghn8/courses/neuroengineering/project/data/patient_%d/ictal train/' % pid\n",
    "    nonictal_data_dir = '/home/ghn8/courses/neuroengineering/project/data/patient_%d/non-ictal train/' % pid\n",
    "    \n",
    "    train_inputs = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1, len(os.listdir(ictal_data_dir))+1):\n",
    "        file_path = os.path.join(ictal_data_dir, 'patient_%d_%d.mat' % (pid, i))\n",
    "        data_mat = sio.loadmat(file_path)\n",
    "        data = data_mat['data'].astype(np.float32)\n",
    "        if(np.isnan(data).any()):\n",
    "            raise(ValueError(\"NaN in ictal data\"))\n",
    "        train_inputs.append(data.T) # transpose data to get num_channels x timepoints\n",
    "        train_labels.append(ICTAL)\n",
    "    \n",
    "    for i in range(1, len(os.listdir(nonictal_data_dir))+1):\n",
    "        file_path = os.path.join(nonictal_data_dir, 'patient_%d_%d.mat' % (pid, i))\n",
    "        data_mat = sio.loadmat(file_path)\n",
    "        data = data_mat['data'].astype(np.float64)\n",
    "        if(np.isnan(data).any()):\n",
    "            raise(ValueError(\"NaN in non-ictal data\"))\n",
    "        train_inputs.append(data.T) # transpose data to get num_channels x timepoints\n",
    "        train_labels.append(NONICTAL)\n",
    "        \n",
    "    train_inputs = np.asarray(train_inputs)\n",
    "    train_labels = np.asarray(train_labels)\n",
    "    \n",
    "    return train_inputs, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_test_data(pid):\n",
    "    test_dir = '/home/ghn8/courses/neuroengineering/project/data/patient_%d/test/' % pid\n",
    "    \n",
    "    test_inputs = []\n",
    "    \n",
    "    for i in range(1, len(os.listdir(test_dir))+1):\n",
    "        file_path = os.path.join(test_dir, 'patient_%d_test_%d.mat' % (pid, i))\n",
    "        if os.path.exists(file_path):\n",
    "            data_mat = sio.loadmat(file_path)\n",
    "            data = data_mat['data'].astype(np.float32)\n",
    "            data = np.nan_to_num(data)\n",
    "            if(np.isnan(data).any()):\n",
    "                raise(ValueError(\"NaN in test data\"))\n",
    "            test_inputs.append(data.T) # transpose data to get num_channels x timepoints\n",
    "        \n",
    "    test_inputs = np.asarray(test_inputs)\n",
    "    \n",
    "    return test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PATIENTS = 7\n",
    "all_train_data = {}\n",
    "\n",
    "train_data_dump_file = os.path.join('/home/ghn8/courses/neuroengineering/project/preprocessed/all_data', 'all_train_data.pkl')\n",
    "\n",
    "if not os.path.exists(train_data_dump_file):\n",
    "    for pid in range(1, NUM_PATIENTS+1):\n",
    "        train_inputs, train_labels = get_patient_training_data(pid)\n",
    "        all_train_data['patient_%d' % pid] = { 'inputs': train_inputs, 'labels': train_labels}\n",
    "        print('Finished reading data for patient %d' % pid)\n",
    "\n",
    "    pickle.dump(all_train_data, open(train_data_dump_file, 'wb'))\n",
    "else:\n",
    "    all_train_data = pickle.load(open(train_data_dump_file, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data = {}\n",
    "\n",
    "test_data_dump_file = os.path.join('/home/ghn8/courses/neuroengineering/project/preprocessed/all_data', 'all_test_data.pkl')\n",
    "\n",
    "if not os.path.exists(test_data_dump_file):\n",
    "    for pid in range(1, NUM_PATIENTS+1):\n",
    "        test_inputs = get_patient_test_data(pid)\n",
    "        all_test_data['patient_%d' % pid] = test_inputs\n",
    "        print('Finished reading test data for patient %d' % pid)\n",
    "\n",
    "    pickle.dump(all_test_data, open(test_data_dump_file, 'wb'))\n",
    "else:\n",
    "    all_test_data = pickle.load(open(test_data_dump_file, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft(timeseries):\n",
    "    return np.log10(np.absolute(np.fft.rfft(timeseries)))\n",
    "\n",
    "def get_spectral_features(timeseries, min_f=1, max_f=50):\n",
    "    raw_fft = fft(timeseries)\n",
    "    mask = np.logical_or(np.isneginf(raw_fft), np.isinf(raw_fft))\n",
    "    raw_fft[mask] = 0.0;\n",
    "    return raw_fft[:, min_f:max_f]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(features, labels):\n",
    "    assert features.shape[0] == labels.shape[0], \"Mismatched number of samples\"\n",
    "    shuffled_indices = np.random.permutation(features.shape[0])\n",
    "    \n",
    "    shuffled_features = features[shuffled_indices, :]\n",
    "    shuffled_labels = labels[shuffled_indices]\n",
    "    return shuffled_features, shuffled_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs_to_spectral_features(inputs, lpf_freq):\n",
    "    num_samples = inputs.shape[0]\n",
    "    features = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = inputs[i, :, :].squeeze()\n",
    "\n",
    "        min_f = 1\n",
    "        max_f = lpf_freq*2 if (sample.shape[1] > 500) else lpf_freq\n",
    "\n",
    "        spectral_features = get_spectral_features(sample, min_f=min_f, max_f=max_f).ravel()\n",
    "        features.append(spectral_features)\n",
    "    features = np.asarray(features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ica_clean(data, n_components):\n",
    "    ica = FastICA(n_components=n_components)\n",
    "    return ica.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temporal_features(inputs, num_eigenvalues=-1, num_icas=0):\n",
    "    num_samples = inputs.shape[0]\n",
    "    features = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = inputs[i, :, :].squeeze()\n",
    "        \n",
    "        if num_icas > 0:\n",
    "            sample = ica_clean(sample, num_icas)\n",
    "        \n",
    "        norm_sample = preprocessing.scale(sample)\n",
    "        corr = np.corrcoef(norm_sample)\n",
    "        \n",
    "        uppper_triag_indices = np.triu_indices(corr.shape[0], 1)\n",
    "        upper_triag_vals = corr[uppper_triag_indices].ravel()\n",
    "        \n",
    "        eigenvalues, _ = np.linalg.eig(corr)\n",
    "        eigenvalues = np.sort(eigenvalues)\n",
    "        \n",
    "        if num_eigenvalues > 0:\n",
    "            eigenvalues = eigenvalues[:num_eigenvalues]\n",
    "\n",
    "        features.append(np.concatenate((upper_triag_vals, eigenvalues)))\n",
    "    features = np.asarray(features)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs_to_features(inputs, lpf_freq=50, n_ica=5):\n",
    "    spectral_features = transform_inputs_to_spectral_features(inputs, lpf_freq)\n",
    "    if n_ica > 0:\n",
    "        spectral_features = ica_clean(spectral_features, n_ica)\n",
    "        \n",
    "    temporal_features = get_temporal_features(inputs)\n",
    "    \n",
    "    features = np.concatenate((spectral_features, spectral_features), axis=1)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_channels_by_patient = { 'patient_1': [0, 2, 60, 61, 76, 83],\n",
    "                         'patient_2': [8, 13, 30, 31, 44],\n",
    "                         'patient_3': [1, 8, 10, 11, 12],\n",
    "                         'patient_4': [2, 39, 70, 71, 87],\n",
    "                         'patient_5': [18, 19, 26, 41, 49, 75],\n",
    "                         'patient_6': [11, 27, 38, 41, 69],\n",
    "                         'patient_7': [6, 7, 20, 25, 28, 50, 60] }\n",
    "\n",
    "for n_estimators in [1000]:\n",
    "    output_file = os.path.join('/home/ghn8/courses/neuroengineering/project/gia/outputs', 'rfc_lpf50+temporal_%de_selected-channels.csv' % n_estimators)\n",
    "    is_testing = True\n",
    "\n",
    "    for pid in range(1, NUM_PATIENTS+1):\n",
    "        patient_label = 'patient_%d' % pid\n",
    "        train_inputs = all_train_data[patient_label]['inputs']\n",
    "        train_labels = all_train_data[patient_label]['labels']\n",
    "        test_inputs = all_test_data[patient_label]\n",
    "        \n",
    "        selected_channels = selected_channels_by_patient[patient_label]\n",
    "        train_inputs = train_inputs[:, selected_channels, :]\n",
    "        test_inputs = test_inputs[:, selected_channels, :]\n",
    "\n",
    "        # hyperparameters\n",
    "        lpf_freq = 50\n",
    "        n_ica = 20 if (pid == 5) else 0\n",
    "        train_features = transform_inputs_to_features(train_inputs, lpf_freq=50, n_ica=0)\n",
    "        test_features = transform_inputs_to_features(test_inputs, lpf_freq=50, n_ica=0)\n",
    "\n",
    "        if is_testing:\n",
    "            print(\"Predicting patient %d\" % pid)\n",
    "            rfc = RandomForestClassifier(n_estimators=n_estimators, bootstrap=False)\n",
    "\n",
    "            # training\n",
    "            rfc.fit(train_features, train_labels)\n",
    "            ictal_pred_probs = rfc.predict_proba(test_features)[:, 1]\n",
    "\n",
    "            if pid == 1:\n",
    "                fh = open(output_file, 'w')\n",
    "                fh.write(\"id,prediction\\n\")\n",
    "            else:\n",
    "                fh = open(output_file, 'a')\n",
    "\n",
    "            for i in range(len(ictal_pred_probs)):\n",
    "                fh.write(\"patient_%d_%d,%f\\n\" % (pid, i+1, ictal_pred_probs[i]))\n",
    "            fh.close()\n",
    "        else:\n",
    "            print(\"Evaluating patient %d\" % pid)\n",
    "            val_fraction = 0.2\n",
    "\n",
    "            # creat training and validation data\n",
    "            [shuffled_features, shuffled_labels] = shuffle_data(train_features, train_labels)\n",
    "\n",
    "            num_samples = train_features.shape[0]\n",
    "            num_val_samples = int(num_samples * val_fraction)\n",
    "\n",
    "            val_features = shuffled_features[:num_val_samples, :]\n",
    "            val_labels = shuffled_labels[:num_val_samples]\n",
    "\n",
    "            bootstraped_train_features = shuffled_features[num_val_samples:, :]\n",
    "            bootstraped_train_labels = shuffled_labels[num_val_samples:]\n",
    "\n",
    "            rfc = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "            # training\n",
    "            rfc.fit(bootstraped_train_features, bootstraped_train_labels)\n",
    "            print(\"Accuracy: \", rfc.score(val_features, val_labels))\n",
    "            val_ictal_probs = rfc.predict_proba(val_features)[:, 1]\n",
    "            print(\"AUC :\", roc_auc_score(val_labels, val_ictal_probs))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
